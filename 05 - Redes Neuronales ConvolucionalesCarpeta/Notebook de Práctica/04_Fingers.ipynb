{"cells":[{"cell_type":"markdown","metadata":{"id":"imz8cowUxp9q"},"source":["# Entrenamiento de un modelo convolucional\n","---\n","**Configuración General del Entorno de Trabajo**\n","\n","Esta sección detecta si el notebook está corriendo en un entorno COLAB o en uno LOCAL . Monta la carpeta de Google Drive si corresponde y define constantes para trabajar de forma general con cualquir script. Modificar las definiciones de las carpetas según el entorno y configuración del mismo."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20739,"status":"ok","timestamp":1696564512484,"user":{"displayName":"Cesar Estrebou","userId":"12510511812709829812"},"user_tz":180},"id":"mralyUB8ta8A","outputId":"47997811-515d-4e22-c727-fee1e721581a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["ColabNotebook = 'google.colab' in str(get_ipython())\n","\n","if ColabNotebook:\n","    # configuración para notebook en COLAB\n","    DRIVE_DIR = '/content/drive/MyDrive/' # carpeta G-Drive\n","    MNT_DRIVE_DIR = '/content/drive/'     # carpeta donde montar G-Drive\n","    # carpeta donde se encuentran archivos .py auxiliares\n","    FUENTES_DIR = '/content/drive/MyDrive/Colab Notebooks/Fuentes'\n","    DATOS_DIR = DRIVE_DIR + 'Datos/'      # carpeta donde se encuentran los datasets\n","\n","    # monta G-drive en entorno COLAB\n","    from google.colab import drive\n","    drive.mount(MNT_DRIVE_DIR)\n","else:\n","    # configuración para notebook con instalación LOCAL\n","\n","\n","    FUENTES_DIR = './RN2022/Fuentes'         # carpeta donde se encuentran archivos .py auxiliares\n","    DATOS_DIR = 'D:/Internet/G-Drive/Datos/' # carpeta donde se encuentran los datasets\n","\n","# agrega ruta de busqueda donde tenemos archivos .py\n","import sys\n","sys.path.append(FUENTES_DIR)"]},{"cell_type":"markdown","metadata":{"id":"0Ly9K2UTJD6N"},"source":["**Construcción del Modelo**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m9JbofDpsG3j","outputId":"fccc0795-e371-4c47-b331-02171141f02b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 31, 31, 8)         80        \n","                                                                 \n"," max_pooling2d (MaxPooling2  (None, 15, 15, 8)         0         \n"," D)                                                              \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 7, 7, 16)          1168      \n","                                                                 \n"," max_pooling2d_1 (MaxPoolin  (None, 3, 3, 16)          0         \n"," g2D)                                                            \n","                                                                 \n"," flatten (Flatten)           (None, 144)               0         \n","                                                                 \n"," dense (Dense)               (None, 10)                1450      \n","                                                                 \n"," dense_1 (Dense)             (None, 6)                 66        \n","                                                                 \n","=================================================================\n","Total params: 2764 (10.80 KB)\n","Trainable params: 2764 (10.80 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Found 14927 images belonging to 6 classes.\n","Found 3731 images belonging to 6 classes.\n","Found 3968 images belonging to 6 classes.\n","Epoch 1/30\n"," 59/467 [==>...........................] - ETA: 40:11 - loss: 1.6936 - accuracy: 0.3215"]}],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten, InputLayer, Conv2D, MaxPooling2D\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import EarlyStopping\n","import matplotlib.pyplot as plt\n","\n","# constantes para arquitectura, generación datos y entrenamiento/validacion\n","EPOCAS = 30\n","LOTES  = 32\n","IMG_SIZE = (64, 64, 1)\n","N_CLASSES = 6\n","PACIENCIA = 10\n","\n","# %% construye le modelo\n","\n","def build_model(img_size, classes):\n","    model = Sequential()\n","\n","    model.add(InputLayer(input_shape=img_size))\n","    model.add(Conv2D(8, kernel_size=(3,3), strides=(2,2), activation='relu'))\n","    model.add(MaxPooling2D(pool_size=(2,2)))\n","    model.add(Conv2D(16, kernel_size=(3,3), strides=(2,2), activation='relu'))\n","    model.add(MaxPooling2D(pool_size=(2,2)))\n","    model.add(Flatten())\n","    model.add(Dense(10, activation = 'tanh'))\n","    model.add(Dense(classes, activation = 'softmax'))\n","\n","    model.summary()\n","    return model\n","\n","# obtiene la arquitectura para el modelo y lo compila\n","model = build_model(IMG_SIZE, N_CLASSES)\n","model.compile('adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n","\n","\n","# %% Entrenamiento del modelo\n","\n","# construye un generador de imagenes para dividir en entrenamiento y validación\n","# aplicando transformaciones para aumentar los datos\n","data_train_generator = ImageDataGenerator(\n","    validation_split=0.2,\n","    rotation_range=45,         # rotacion\n","    # zoom_range=0.15,         # zoom\n","    # width_shift_range=0.1,   # desplazamiento horizontal\n","    # height_shift_range=0.1,  # desplazamiento vertical\n","    # shear_range=0.15,        #\n","    # horizontal_flip=False,   # espejo horizontal\n","    #vertical_flip=False,      # espejo vertical\n","    fill_mode=\"nearest\"\n","    )\n","\n","# generador para entrenamiento a partir de la carpeta indicada en IMAGES_DIR\n","train_iter = data_train_generator.flow_from_directory(\n","            target_size=(IMG_SIZE[0],IMG_SIZE[1]),\n","            directory=DATOS_DIR+'Fingers/train',\n","            class_mode='categorical',\n","            batch_size=LOTES,\n","            color_mode='grayscale',\n","            subset='training'   # asigna subconjunto segun validation_split del ImageDataGenerator\n","            )\n","\n","valid_iter = data_train_generator.flow_from_directory(\n","            target_size=(IMG_SIZE[0],IMG_SIZE[1]),\n","            directory=DATOS_DIR+'Fingers/train',\n","            class_mode='categorical',\n","            batch_size=LOTES,\n","            color_mode='grayscale',\n","            subset='validation' # asigna subconjunto segun validation_split del ImageDataGenerator\n","            )\n","\n","\n","data_test_generator = ImageDataGenerator(\n","    rotation_range=45,         # rotacion\n","    # zoom_range=0.15,         # zoom\n","    # width_shift_range=0.1,   # desplazamiento horizontal\n","    # height_shift_range=0.1,  # desplazamiento vertical\n","    # shear_range=0.15,        #\n","    # horizontal_flip=False,   # espejo horizontal\n","    #vertical_flip=False,      # espejo vertical\n","    fill_mode=\"nearest\"\n","    )\n","\n","test_iter = data_test_generator.flow_from_directory(\n","            target_size=(IMG_SIZE[0],IMG_SIZE[1]),\n","            directory=DATOS_DIR+'Fingers/test',\n","            class_mode='categorical',\n","            color_mode='grayscale',\n","            batch_size=LOTES\n","            )\n","\n","# Callback para parada temprana\n","early_stop = EarlyStopping(monitor='val_loss',\n","                           patience=PACIENCIA,\n","                           restore_best_weights=True)\n","\n","H = model.fit(\n","    train_iter,\n","    validation_data=valid_iter,\n","    validation_steps= 10,\n","    epochs=EPOCAS,\n","    callbacks=[early_stop])\n","\n","# dibuja accuracy del progreso del entrenamiento\n","fig, axs = plt.subplots(1,2, figsize=(20,6))\n","plt.figure()\n","axs[0].plot(H.history[\"loss\"], label=\"train_loss\")\n","axs[0].plot(H.history[\"val_loss\"], label=\"val_loss\")\n","\n","axs[1].plot(H.history[\"accuracy\"], label=\"train_acc\")\n","axs[1].plot(H.history[\"val_accuracy\"], label=\"val_acc\")\n","\n","# %% evalua el modelo para entrenamiento\n","pred = model.evaluate(train_iter, verbose=0)\n","print(\"\\nEfectividad del modelo con datos de entrenamiento: %6.2f%%\" % (pred[1]*100))\n","\n","# evalua el modelo con los datos de testeo\n","pred = model.evaluate(valid_iter, verbose=0)\n","print(\"Efectividad del modelo con datos de Validación...: %6.2f%%\" % (pred[1]*100))\n","\n","# evalua el modelo con los datos de testeo\n","pred = model.evaluate(test_iter, verbose=0)\n","print(\"Efectividad del modelo con datos de Prueba.......: %6.2f%%\" % (pred[1]*100))\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.15"},"varInspector":{"cols":{"lenName":"16","lenType":"16","lenVar":"50"},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat":4,"nbformat_minor":0}